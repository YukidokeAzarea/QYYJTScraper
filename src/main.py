"""
ä¼ç ”é€šåŸæŠ•å€ºå‹Ÿé›†è¯´æ˜ä¹¦çˆ¬è™«ä¸»ç¨‹åº
æ”¯æŒæ‰¹é‡å¤„ç†ã€é˜²ä¼‘çœ ã€åçˆ¬è™«æœºåˆ¶
"""

import os
import sys
import time
import random
import json
import pandas as pd
import ctypes
from pathlib import Path
from typing import List, Dict, Optional
from loguru import logger
from tqdm import tqdm

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent))

from .scraper import QYYJTScraper
from .database import DatabaseManager
from .smart_pool import SmartAccountPool
from .config import *


class ProductionScraper:
    """ç”Ÿäº§ç¯å¢ƒçˆ¬è™«ä¸»ç±»"""
    
    def __init__(self):
        self.smart_pool = SmartAccountPool()  # ä½¿ç”¨æ™ºèƒ½è´¦å·æ± 
        self.db = DatabaseManager()
        self.db.connect()  # è¿æ¥æ•°æ®åº“
        self.processed_count = 0
        self.error_count = 0
        self.start_time = None
        self.error_log = []  # é”™è¯¯æ—¥å¿—
        self.processed_bonds = set()  # å·²å¤„ç†çš„å€ºåˆ¸é›†åˆ
        self.progress_file = "data/progress.json"
        self.error_file = "data/error_log.json"
        self.resume_file = "data/pause.flag"
        
    def prevent_sleep(self):
        """é˜²æ­¢ç”µè„‘ä¼‘çœ """
        try:
            # Windowsç³»ç»Ÿé˜²æ­¢ä¼‘çœ 
            if os.name == 'nt':
                ctypes.windll.kernel32.SetThreadExecutionState(0x80000000 | 0x00000001)
                logger.info("âœ… å·²å¯ç”¨é˜²ä¼‘çœ æ¨¡å¼")
            else:
                # Linux/Macç³»ç»Ÿ
                logger.info("âš ï¸ éWindowsç³»ç»Ÿï¼Œè¯·æ‰‹åŠ¨è®¾ç½®é˜²æ­¢ä¼‘çœ ")
        except Exception as e:
            logger.warning(f"âš ï¸ é˜²ä¼‘çœ è®¾ç½®å¤±è´¥: {e}")
    
    def restore_sleep(self):
        """æ¢å¤ç”µè„‘ä¼‘çœ """
        try:
            if os.name == 'nt':
                ctypes.windll.kernel32.SetThreadExecutionState(0x80000000)
                logger.info("âœ… å·²æ¢å¤ä¼‘çœ æ¨¡å¼")
        except Exception as e:
            logger.warning(f"âš ï¸ æ¢å¤ä¼‘çœ è®¾ç½®å¤±è´¥: {e}")
    
    def random_delay(self, min_delay: float = 2.0, max_delay: float = 4.0):
        """éšæœºå»¶è¿Ÿï¼Œé˜²æ­¢åçˆ¬è™«"""
        delay = random.uniform(min_delay, max_delay)
        logger.debug(f"â³ éšæœºå»¶è¿Ÿ {delay:.2f} ç§’")
        time.sleep(delay)
    
    def load_bonds_list(self) -> List[Dict]:
        """åŠ è½½å€ºåˆ¸åˆ—è¡¨"""
        try:
            logger.info(f"ğŸ“– æ­£åœ¨åŠ è½½å€ºåˆ¸åˆ—è¡¨: {BONDS_LIST_PATH}")
            df = pd.read_excel(BONDS_LIST_PATH)
            
            # æ£€æŸ¥å¿…è¦çš„åˆ—
            if 'å€ºåˆ¸ç®€ç§°' not in df.columns:
                raise ValueError("Excelæ–‡ä»¶ä¸­ç¼ºå°‘'å€ºåˆ¸ç®€ç§°'åˆ—")
            
            # è¿‡æ»¤æ‰ç©ºå€¼
            df = df.dropna(subset=['å€ºåˆ¸ç®€ç§°'])
            
            bonds = []
            for _, row in df.iterrows():
                bond_info = {
                    'bond_short_name': str(row['å€ºåˆ¸ç®€ç§°']).strip(),
                    'bond_code': str(row.get('ä»£ç ', '')).strip() if pd.notna(row.get('ä»£ç ')) else '',
                    'issuer': str(row.get('å‘è¡Œäºº', '')).strip() if pd.notna(row.get('å‘è¡Œäºº')) else '',
                    'bond_type': str(row.get('å€ºåˆ¸ç±»å‹', '')).strip() if pd.notna(row.get('å€ºåˆ¸ç±»å‹')) else '',
                    'province': str(row.get('å‘è¡Œäººçœä»½', '')).strip() if pd.notna(row.get('å‘è¡Œäººçœä»½')) else '',
                    'city': str(row.get('å‘è¡ŒäººåŸå¸‚', '')).strip() if pd.notna(row.get('å‘è¡ŒäººåŸå¸‚')) else '',
                }
                bonds.append(bond_info)
            
            logger.info(f"âœ… æˆåŠŸåŠ è½½ {len(bonds)} ä¸ªå€ºåˆ¸")
            return bonds
            
        except Exception as e:
            logger.error(f"âŒ åŠ è½½å€ºåˆ¸åˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    def process_single_bond(self, bond_info: Dict, progress_bar: tqdm) -> bool:
        """å¤„ç†å•ä¸ªå€ºåˆ¸"""
        bond_name = bond_info['bond_short_name']
        
        try:
            logger.info(f"ğŸ” æ­£åœ¨å¤„ç†å€ºåˆ¸: {bond_name}")
            
            # éšæœºå»¶è¿Ÿ
            self.random_delay()
            
            # ä½¿ç”¨æ™ºèƒ½è´¦å·æ± å¤„ç†å€ºåˆ¸
            success, result = self.smart_pool.process_bond_with_retry(bond_name)
            if not success:
                error_msg = f"æ™ºèƒ½è´¦å·æ± å¤„ç†å¤±è´¥: {bond_name}"
                logger.warning(f"âš ï¸ {error_msg}")
                self._log_error(bond_name, error_msg, "SMART_POOL_FAILED")
                return False
            
            # è·å–è§£æçš„æ–‡æ¡£
            documents = result.get('documents', [])
            if not documents:
                error_msg = f"æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£: {bond_name}"
                logger.warning(f"âš ï¸ {error_msg}")
                self._log_error(bond_name, error_msg, "NO_DOCUMENTS")
                return False
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            success_count = 0
            for doc in documents:
                try:
                    # æ·»åŠ é¢å¤–çš„å€ºåˆ¸ä¿¡æ¯åˆ°æ–‡æ¡£æ•°æ®ï¼ˆä¸è¦†ç›–APIè§£æçš„ä¿¡æ¯ï¼‰
                    doc.update({
                        'province': bond_info.get('province', ''),
                        'city': bond_info.get('city', ''),
                    })
                    
                    # æ’å…¥æ•°æ®åº“
                    success = self.db.insert_document(doc)
                    if success:
                        success_count += 1
                        logger.debug(f"âœ… ä¿å­˜æ–‡æ¡£: {doc.get('document_title', 'Unknown')}")
                    
                except Exception as e:
                    error_msg = f"ä¿å­˜æ–‡æ¡£å¤±è´¥: {doc.get('document_title', 'Unknown')} - {str(e)}"
                    logger.error(f"âŒ {error_msg}")
                    self._log_error(bond_name, error_msg, "SAVE_FAILED", doc.get('document_title', ''))
                    continue
            
            if success_count > 0:
                logger.info(f"âœ… æˆåŠŸå¤„ç†å€ºåˆ¸ {bond_name}: {success_count} ä¸ªæ–‡æ¡£")
                self.processed_count += 1
                self.processed_bonds.add(bond_name)
                return True
            else:
                error_msg = f"å€ºåˆ¸ {bond_name} æ²¡æœ‰æˆåŠŸä¿å­˜ä»»ä½•æ–‡æ¡£"
                logger.warning(f"âš ï¸ {error_msg}")
                self._log_error(bond_name, error_msg, "NO_SUCCESSFUL_SAVES")
                return False
                
        except Exception as e:
            error_msg = f"å¤„ç†å€ºåˆ¸ {bond_name} å¤±è´¥: {str(e)}"
            logger.error(f"âŒ {error_msg}")
            self._log_error(bond_name, error_msg, "PROCESSING_ERROR")
            self.error_count += 1
            return False
        finally:
            progress_bar.update(1)
    
    def _log_error(self, bond_name: str, error_msg: str, error_type: str, document_title: str = ""):
        """è®°å½•é”™è¯¯åˆ°æ—¥å¿—"""
        error_entry = {
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'bond_name': bond_name,
            'error_type': error_type,
            'error_message': error_msg,
            'document_title': document_title
        }
        self.error_log.append(error_entry)
        
        # æ¯100ä¸ªé”™è¯¯ä¿å­˜ä¸€æ¬¡
        if len(self.error_log) % 100 == 0:
            self._save_error_log()
    
    def _save_error_log(self):
        """ä¿å­˜é”™è¯¯æ—¥å¿—åˆ°æ–‡ä»¶"""
        try:
            os.makedirs(os.path.dirname(self.error_file), exist_ok=True)
            with open(self.error_file, 'w', encoding='utf-8') as f:
                json.dump(self.error_log, f, ensure_ascii=False, indent=2)
            logger.debug(f"ğŸ’¾ é”™è¯¯æ—¥å¿—å·²ä¿å­˜: {self.error_file}")
        except Exception as e:
            logger.warning(f"âš ï¸ ä¿å­˜é”™è¯¯æ—¥å¿—å¤±è´¥: {e}")
    
    def _load_progress(self) -> Dict:
        """åŠ è½½è¿›åº¦æ–‡ä»¶"""
        try:
            if os.path.exists(self.progress_file):
                with open(self.progress_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            logger.warning(f"âš ï¸ åŠ è½½è¿›åº¦æ–‡ä»¶å¤±è´¥: {e}")
        return {}
    
    def _save_progress(self, current: int, total: int):
        """ä¿å­˜è¿›åº¦åˆ°æ–‡ä»¶"""
        try:
            os.makedirs(os.path.dirname(self.progress_file), exist_ok=True)
            progress_data = {
                'current': current,
                'total': total,
                'processed_count': self.processed_count,
                'error_count': self.error_count,
                'processed_bonds': list(self.processed_bonds),
                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
                'start_time': self.start_time
            }
            
            with open(self.progress_file, 'w', encoding='utf-8') as f:
                json.dump(progress_data, f, ensure_ascii=False, indent=2)
            
            logger.debug(f"ğŸ’¾ è¿›åº¦å·²ä¿å­˜: {self.progress_file}")
        except Exception as e:
            logger.warning(f"âš ï¸ ä¿å­˜è¿›åº¦å¤±è´¥: {e}")
    
    def _create_pause_file(self):
        """åˆ›å»ºæš‚åœæ–‡ä»¶"""
        try:
            os.makedirs(os.path.dirname(self.resume_file), exist_ok=True)
            with open(self.resume_file, 'w') as f:
                f.write(time.strftime('%Y-%m-%d %H:%M:%S'))
            logger.info(f"â¸ï¸ æš‚åœæ–‡ä»¶å·²åˆ›å»º: {self.resume_file}")
        except Exception as e:
            logger.warning(f"âš ï¸ åˆ›å»ºæš‚åœæ–‡ä»¶å¤±è´¥: {e}")
    
    def _remove_pause_file(self):
        """åˆ é™¤æš‚åœæ–‡ä»¶"""
        try:
            if os.path.exists(self.resume_file):
                os.remove(self.resume_file)
                logger.info(f"âœ… æš‚åœæ–‡ä»¶å·²åˆ é™¤: {self.resume_file}")
        except Exception as e:
            logger.warning(f"âš ï¸ åˆ é™¤æš‚åœæ–‡ä»¶å¤±è´¥: {e}")
    
    def run_batch_processing(self, start_index: int = 0, max_bonds: Optional[int] = None, 
                           resume_from_file: str = None, resume: bool = False, force: bool = False):
        """æ‰¹é‡å¤„ç†å€ºåˆ¸"""
        try:
            # é˜²æ­¢ä¼‘çœ 
            self.prevent_sleep()
            
            # åŠ è½½å€ºåˆ¸åˆ—è¡¨
            bonds = self.load_bonds_list()
            if not bonds:
                logger.error("âŒ æ²¡æœ‰å¯å¤„ç†çš„å€ºåˆ¸")
                return
            
            # æ–­ç‚¹ç»­ä¼ é€»è¾‘
            if resume:
                progress_data = self._load_progress()
                if progress_data:
                    start_index = progress_data.get('current', 0)
                    self.processed_count = progress_data.get('processed_count', 0)
                    self.error_count = progress_data.get('error_count', 0)
                    self.processed_bonds = set(progress_data.get('processed_bonds', []))
                    
                    # æ£€æŸ¥æ˜¯å¦å·²å®Œæˆæ‰€æœ‰å€ºåˆ¸ï¼ˆä½¿ç”¨åŸå§‹å€ºåˆ¸åˆ—è¡¨é•¿åº¦ï¼‰
                    if start_index >= len(bonds):
                        logger.info("âœ… æ‰€æœ‰å€ºåˆ¸éƒ½å·²å¤„ç†å®Œæˆ")
                        return
                    
                    logger.info(f"ğŸ”„ æ–­ç‚¹ç»­ä¼ ï¼šä»ç¬¬ {start_index + 1} ä¸ªå€ºåˆ¸å¼€å§‹")
                    logger.info(f"ğŸ“Š å·²å¤„ç†: {self.processed_count} ä¸ªï¼Œé”™è¯¯: {self.error_count} ä¸ª")
                    
                    # åº”ç”¨æ–­ç‚¹ç»­ä¼ çš„ç´¢å¼•è°ƒæ•´
                    bonds = bonds[start_index:]
                    logger.info(f"ğŸ“Š ä»ç¬¬ {start_index + 1} ä¸ªå€ºåˆ¸å¼€å§‹å¤„ç†")
            
            # æ£€æŸ¥æ•°æ®åº“ä¸­å·²å­˜åœ¨çš„å€ºåˆ¸ï¼Œé¿å…é‡å¤çˆ¬å–
            if not force:
                logger.info("ğŸ” æ£€æŸ¥æ•°æ®åº“ä¸­å·²å­˜åœ¨çš„å€ºåˆ¸...")
                existing_bonds = self.db.get_existing_bond_short_names()
                if existing_bonds:
                    original_count = len(bonds)
                    bonds = [bond for bond in bonds if bond['bond_short_name'] not in existing_bonds]
                    filtered_count = original_count - len(bonds)
                    logger.info(f"ğŸ’¾ æ•°æ®åº“ä¸­å·²å­˜åœ¨ {len(existing_bonds)} ä¸ªå€ºåˆ¸çš„æ•°æ®")
                    logger.info(f"â­ï¸ è·³è¿‡å·²çˆ¬å–çš„ {filtered_count} ä¸ªå€ºåˆ¸ï¼ŒèŠ‚çœAPIè¯·æ±‚æ¬¡æ•°")
                    
                    # æ˜¾ç¤ºå·²å­˜åœ¨å€ºåˆ¸çš„æ–‡æ¡£ç»Ÿè®¡
                    if filtered_count > 0:
                        logger.info("ğŸ“Š å·²å­˜åœ¨å€ºåˆ¸çš„æ–‡æ¡£ç»Ÿè®¡ï¼ˆå‰10ä¸ªï¼‰ï¼š")
                        count = 0
                        for bond in existing_bonds:
                            if count >= 10:
                                break
                            doc_count = self.db.get_bond_document_count(bond)
                            logger.info(f"  - {bond}: {doc_count} ä¸ªæ–‡æ¡£")
                            count += 1
                        if len(existing_bonds) > 10:
                            logger.info(f"  ... è¿˜æœ‰ {len(existing_bonds) - 10} ä¸ªå€ºåˆ¸")
            else:
                logger.warning("âš ï¸ å¼ºåˆ¶æ¨¡å¼ï¼šå°†é‡æ–°çˆ¬å–æ‰€æœ‰å€ºåˆ¸ï¼ˆåŒ…æ‹¬å·²å­˜åœ¨çš„ï¼‰")
                existing_bonds = self.db.get_existing_bond_short_names()
                if existing_bonds:
                    logger.info(f"ğŸ’¾ æ•°æ®åº“ä¸­å·²å­˜åœ¨ {len(existing_bonds)} ä¸ªå€ºåˆ¸çš„æ•°æ®ï¼Œä½†å°†é‡æ–°çˆ¬å–")
            
            if max_bonds:
                bonds = bonds[:max_bonds]
                logger.info(f"ğŸ“Š é™åˆ¶å¤„ç† {max_bonds} ä¸ªå€ºåˆ¸")
            
            # è¿‡æ»¤å·²å¤„ç†çš„å€ºåˆ¸ï¼ˆæ–­ç‚¹ç»­ä¼ ï¼‰
            # æ³¨æ„ï¼šè¿™é‡Œä¸éœ€è¦å†æ¬¡è¿‡æ»¤ï¼Œå› ä¸ºå·²ç»åœ¨ä¸Šé¢é€šè¿‡æ•°æ®åº“æ£€æŸ¥è¿‡æ»¤è¿‡äº†
            # if resume and self.processed_bonds:
            #     original_count = len(bonds)
            #     bonds = [bond for bond in bonds if bond['bond_short_name'] not in self.processed_bonds]
            #     filtered_count = original_count - len(bonds)
            #     if filtered_count > 0:
            #         logger.info(f"â­ï¸ è·³è¿‡æ–­ç‚¹ç»­ä¼ ä¸­å·²å¤„ç†çš„ {filtered_count} ä¸ªå€ºåˆ¸")
            
            total_bonds = len(bonds)
            if total_bonds == 0:
                logger.info("âœ… æ‰€æœ‰å€ºåˆ¸éƒ½å·²å¤„ç†å®Œæˆ")
                return
            
            logger.info(f"ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç† {total_bonds} ä¸ªå€ºåˆ¸")
            
            # åˆå§‹åŒ–æ™ºèƒ½è´¦å·æ± 
            logger.info("ğŸ” æ­£åœ¨åˆå§‹åŒ–æ™ºèƒ½è´¦å·æ± ...")
            if not self.smart_pool.initialize():
                logger.error("âŒ æ™ºèƒ½è´¦å·æ± åˆå§‹åŒ–å¤±è´¥ï¼Œæ— æ³•ç»§ç»­å¤„ç†")
                return
            logger.info("âœ… æ™ºèƒ½è´¦å·æ± åˆå§‹åŒ–æˆåŠŸï¼")
            
            # è®°å½•å¼€å§‹æ—¶é—´
            self.start_time = time.time()
            
            # åˆ›å»ºè¿›åº¦æ¡
            progress_bar = tqdm(
                total=total_bonds,
                desc="å¤„ç†å€ºåˆ¸",
                unit="ä¸ª",
                ncols=100,
                colour='green'
            )
            
            # å¤„ç†æ¯ä¸ªå€ºåˆ¸
            for i, bond_info in enumerate(bonds):
                try:
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦æš‚åœ
                    if resume_from_file and os.path.exists(resume_from_file):
                        logger.info("â¸ï¸ æ£€æµ‹åˆ°æš‚åœæ–‡ä»¶ï¼Œåœæ­¢å¤„ç†")
                        self._create_pause_file()
                        break
                    
                    # å¤„ç†å•ä¸ªå€ºåˆ¸
                    success = self.process_single_bond(bond_info, progress_bar)
                    
                    # æ¯å¤„ç†50ä¸ªå€ºåˆ¸æ˜¾ç¤ºä¸€æ¬¡ç»Ÿè®¡
                    if (i + 1) % 50 == 0:
                        self._show_progress_stats(i + 1, total_bonds)
                    
                    # æ¯å¤„ç†100ä¸ªå€ºåˆ¸ä¿å­˜ä¸€æ¬¡è¿›åº¦
                    if (i + 1) % 100 == 0:
                        self._save_progress(start_index + i + 1, start_index + total_bonds)
                    
                except KeyboardInterrupt:
                    logger.info("â¸ï¸ ç”¨æˆ·ä¸­æ–­å¤„ç†")
                    self._create_pause_file()
                    break
                except Exception as e:
                    error_msg = f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
                    logger.error(f"âŒ {error_msg}")
                    self._log_error(bond_info['bond_short_name'], error_msg, "BATCH_ERROR")
                    self.error_count += 1
                    continue
            
            # å…³é—­è¿›åº¦æ¡
            progress_bar.close()
            
            # ä¿å­˜æœ€ç»ˆè¿›åº¦å’Œé”™è¯¯æ—¥å¿—
            self._save_progress(start_index + total_bonds, start_index + total_bonds)
            self._save_error_log()
            
            # åˆ é™¤æš‚åœæ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            self._remove_pause_file()
            
            # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
            self._show_final_stats()
            
        except Exception as e:
            logger.error(f"âŒ æ‰¹é‡å¤„ç†å¤±è´¥: {e}")
            self._create_pause_file()
        finally:
            # æ¢å¤ä¼‘çœ 
            self.restore_sleep()
            # å…³é—­èµ„æº
            self.cleanup()
    
    def _show_progress_stats(self, current: int, total: int):
        """æ˜¾ç¤ºè¿›åº¦ç»Ÿè®¡"""
        elapsed = time.time() - self.start_time
        rate = current / elapsed if elapsed > 0 else 0
        eta = (total - current) / rate if rate > 0 else 0
        
        logger.info(f"ğŸ“Š è¿›åº¦ç»Ÿè®¡: {current}/{total} ({current/total*100:.1f}%) | "
                   f"æˆåŠŸ: {self.processed_count} | é”™è¯¯: {self.error_count} | "
                   f"é€Ÿåº¦: {rate:.1f}ä¸ª/ç§’ | é¢„è®¡å‰©ä½™: {eta/60:.1f}åˆ†é’Ÿ")
    
    
    def _show_final_stats(self):
        """æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡"""
        if self.start_time:
            elapsed = time.time() - self.start_time
            rate = self.processed_count / elapsed if elapsed > 0 else 0
            
            logger.info("=" * 60)
            logger.info("ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆï¼")
            logger.info(f"ğŸ“Š æ€»å¤„ç†æ—¶é—´: {elapsed/3600:.2f} å°æ—¶")
            logger.info(f"âœ… æˆåŠŸå¤„ç†: {self.processed_count} ä¸ªå€ºåˆ¸")
            logger.info(f"âŒ å¤„ç†å¤±è´¥: {self.error_count} ä¸ªå€ºåˆ¸")
            logger.info(f"âš¡ å¹³å‡é€Ÿåº¦: {rate:.2f} ä¸ªå€ºåˆ¸/ç§’")
            logger.info("=" * 60)
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            if self.smart_pool:
                self.smart_pool.cleanup()
            if self.db:
                self.db.close()
            logger.info("ğŸ§¹ èµ„æºæ¸…ç†å®Œæˆ")
        except Exception as e:
            logger.warning(f"âš ï¸ èµ„æºæ¸…ç†å¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ä¼ç ”é€šåŸæŠ•å€ºå‹Ÿé›†è¯´æ˜ä¹¦çˆ¬è™«')
    parser.add_argument('--start', type=int, default=0, help='å¼€å§‹å¤„ç†çš„å€ºåˆ¸ç´¢å¼•')
    parser.add_argument('--max', type=int, help='æœ€å¤§å¤„ç†æ•°é‡')
    parser.add_argument('--resume', action='store_true', help='æ–­ç‚¹ç»­ä¼ æ¨¡å¼')
    parser.add_argument('--pause', type=str, help='æš‚åœæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--test', action='store_true', help='æµ‹è¯•æ¨¡å¼ï¼ˆåªå¤„ç†1ä¸ªå€ºåˆ¸ï¼‰')
    parser.add_argument('--force', action='store_true', help='å¼ºåˆ¶é‡æ–°çˆ¬å–æ‰€æœ‰å€ºåˆ¸ï¼ˆåŒ…æ‹¬å·²å­˜åœ¨çš„ï¼‰')
    
    args = parser.parse_args()
    
    # æµ‹è¯•æ¨¡å¼
    if args.test:
        args.max = 1
        logger.info("ğŸ§ª æµ‹è¯•æ¨¡å¼ï¼šåªå¤„ç†1ä¸ªå€ºåˆ¸")
    
    # åˆ›å»ºç”Ÿäº§çˆ¬è™«å®ä¾‹
    scraper = ProductionScraper()
    
    try:
        # å¼€å§‹æ‰¹é‡å¤„ç†
        scraper.run_batch_processing(
            start_index=args.start,
            max_bonds=args.max,
            resume_from_file=args.pause,
            resume=args.resume,
            force=args.force
        )
    except KeyboardInterrupt:
        logger.info("â¸ï¸ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºè¿è¡Œå¤±è´¥: {e}")
    finally:
        scraper.cleanup()


if __name__ == "__main__":
    main()
